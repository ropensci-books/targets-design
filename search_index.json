[["index.html", "The targets R Package Design Specification Chapter 1 Introduction 1.1 Design", " The targets R Package Design Specification Will Landau Copyright Eli Lilly and Company Chapter 1 Introduction The targets package is a Make-like pipeline toolkit for Statistics and data science in R. With targets, you can maintain a reproducible workflow without repeating yourself. targets learns how your pipeline fits together, skips costly runtime for tasks that are already up to date, runs only the necessary computation, supports implicit parallel computing, abstracts files as R objects, and shows tangible evidence that the results match the underlying code and data. 1.1 Design targets has an elaborate structure to support its advanced features while ensuring decent performance. This bookdown site is a design specification to explain the major aspects of the internal architecture, including the data storage model, object oriented design, and orchestration and branching model. "],["data.html", "Chapter 2 Data and metadata management 2.1 File system 2.2 Targets 2.3 Progress 2.4 Metadata 2.5 Skipping up-to-date targets 2.6 Databases", " Chapter 2 Data and metadata management Like its predecessor, drake, the targets package Abstracts files as R objects. Records the real-time progress of targets as they are running. Records special metadata in order to skip targets that are already up to date. Unlike drake, which outsources data and metadata management to an external package, targets has an entirely custom internal data system. targets goes out of its way to reduce the number of files in storage, centralize the progress data and metadata, assign informative file names, and expose the file system to the user. This approach increases efficiency and portability, and it helps users understand and take control of their data. 2.1 File system When a targets pipeline runs, it creates a folder called _targets to store all the files it needs. _targets/ ├── meta/ ├────── progress ├────── meta ├── objects/ ├────── target1 ├────── target2 ├────── branching_target_c7bcb4bd ├────── branching_target_285fb6a9 ├────── branching_target_874ca381 └── scratch/ # Temporary files deleted at the end of tar_make(). The number of files equals the number of targets plus two, which makes projects easier to upload and share among collaborators than drake’s .drake/ cache. (Files in _targets/scratch/ do not count because they can all be safely deleted after tar_make().) However, these files may still be too large and too numerous for code-specific version control systems like Git. For such projects, it may be more appropriate to share caches through external version-aware platforms such as Dropbox, Microsoft OneDrive, and Google Docs. 2.2 Targets With the exception of dynamic files, the return value of each target lives in its own file inside _targets/objects/. The file name is the name of the target, and there is no file extension. The metadata keeps track of the storage format that governs how to read and write the target’s data. The default format is RDS, so if target x has no explicit format, then readRDS(\"_targets/objects/x\") will read the data. (However, we state this just for the sake of understanding. The recommended way to read data is tar_read(), which takes the storage format into account.) 2.3 Progress The file _targets/meta/progress is a pipe-separated flat file with the name of each target and it’s current runtime progress (running, built, cancelled, or errored). The information in this file helps users keep track of what the pipeline is doing at a given moment. targets periodically appends rows to _targets/meta/progress as the pipeline progresses, so duplicated names usually appear. For any target with duplicated rows in _targets/meta/progress, only the lowest row is valid. In most situations, the progress file can be safely excluded from version control. Functions like tar_graph() use progress information, but it is not essential to the reproducible end product. 2.4 Metadata targets uses special metadata to decide which targets are up to date and which need to run. The metadata file _targets/meta/meta is a flat file with one row for every target and every global object relevant to the pipeline. targets appends new rows to this file as the pipeline progresses. Unlike drake, the metadata is centralized and compatible with data.table, which makes it far faster to check which targets are up to date. In addition, the metadata system allows targets to check not only for up-to-date targets, but also up-to-date global objects, which makes it easier for the user to understand why a target is outdated. _targets/meta/meta has the following columns. Global objects use only the name, type, and data fields. name: Name of the object or target. type: Class name of the object or target. data: Hash of the global object or the file containing the target’s return value. command: Hash of the R command to run the target. depend: Composite hash of all the target’s immediate upstream dependencies. seed: Random number generator seed of the target. A target seed is unique and deterministically generated from its name. path: The file path where the return value is stored. For dynamic files, this field could include multiple character strings. time: Character, hash of the maximum of all the time stamps of the files in path. size: Character, hash of the total file size of all the target’s files in path. bytes: Numeric, total file size in bytes of all the target’s files in path. format: Name of the storage format of the target. User-specified with tar_target() or tar_option_set(). iteration: Iteration mode of the target’s value, either \"vector\" or \"list\". User-specified with tar_target() or tar_option_set(). parent: Name of the parent pattern of the target if the target is a branch. children: For patterns and branching stems, this field has the names of all the branches and buds. Can contain multiple character strings. Empty for branches and non-branching stems. seconds: Runtime of the target in seconds. warnings: Warning messages thrown when the target ran. error: Error message thrown when the target ran. These fields are pipe-separated in the flat file. Fields path and children can have multiple character strings, and these character strings are separated by asterisks in storage. (In memory, path and children are list columns.) 2.5 Skipping up-to-date targets targets uses the metadata to decide if a target is up to date. The should_run() method of the builder class manages this. A target is outdated if one of the following conditions is met. targets checks these rules in the order given below. There is a special cue class to allow the user to customize / suppress most of these rules. There is no metadata record of the target. The target errored last run. The target has a different class than it did before. The cue mode equals \"always\". The cue mode does not equal \"never\". The command metadata field (the hash of the R command) is different from last time. The depend metadata field (the hash of the immediate upstream dependency targets and global objects) is different from last time. The storage format (user-specified with tar_target() or tar_option_set()) is different from last time. The iteration method (user-specified with tar_target() or tar_option_set()) is different from last time. A target’s file (either the one in _targets/objects/ or a dynamic file) does not exist or changed since last time. A target’s dependencies can include functions, and these functions are tracked for changes using a custom hashing procedure. When a function’s hash changes, the function is considered invalidated, and so are any downstream targets with the depend cue turned on. The targets package computes the hash of a function in the following way. 1. Deparse the function with targets:::safe_deparse(). This function computes a string representation of the function that removes comments and standardizes whitespace so that trivial changes to formatting do not cue targets to rerun. 1. Manually remove any literal pointers from the function string using targets:::mask_pointers(). Such pointers arise from inline compiled C/C++ functions. 1. Compute a hash on the preprocessed string above using targets:::digest_chr64(). Those functions themselves have dependencies, and those dependencies are detected with codetools::findGlobals(). Dependencies of functions may include other global functions or global objects. If a dependency of a function is invalidated, the function itself is invalidated, and so are any dependent targets with the depend cue turned on. 2.6 Databases targets manages _targets/meta/progress and _targets/meta/meta with an internal database class, which has methods to read, write, and deduplicate entire datasets as well as row-append records for individual targets. To maximize performance, targets uses fread() and fwrite() from data.table when working with entire databases and base::write() to append individual rows. The database class also supports and internal in-memory cache in order to avoid costly interactions with storage. Internal classes progress and meta each have a database object and methods specific to the use case. And for additional safety, the record class encapsulates and validates individual rows of metadata. "],["classes.html", "Chapter 3 Major internal classes 3.1 Algorithm class 3.2 Pipeline class 3.3 Scheduler class 3.4 Graph class 3.5 Progress class 3.6 Queue class 3.7 Counter class 3.8 Target class 3.9 Stem class 3.10 Bud class 3.11 Pattern class 3.12 Branch class 3.13 Builder class 3.14 Junction class", " Chapter 3 Major internal classes targets relies heavily on object-oriented programming, and the following subsections describe the major classes of objects relevant to orchestration and branching. Objects that appear once per workflow are instances of R6 classes. To maximize performance, target-specific data structures are lower-tech classes: simple environments with formal constructors, helpers, and validators. 3.1 Algorithm class An algorithm in targets is an abstract class that represents how to iterate through the pipeline target by target. Different algorithms describe different kinds of deployment: for example, execution in the main process on the host machine versus parallel execution on a cluster. Every algorithm has a scheduler object and a pipeline object. 3.2 Pipeline class A pipeline is a wrapper around a collection of targets, and it is responsible for the initial reasoning about the topology of the pipeline before runtime. Pipelines express their reasoning by producing static graphs and scheduler objects early on. In addition, pipelines contain new buds and branches created dynamically during the pipeline. 3.3 Scheduler class Whereas pipelines are responsible for static topology, schedulers are responsible for dynamic topology. Schedulers know The upstream and downstream neighbors of each target. The progress of each target, e.g. queued, running, or finished. How many upstream dependencies need to be checked or built before a target is ready to run. To meet these responsibilities, the scheduler is composed of three smaller objects: A graph object. A progress object. A priority queue. 3.4 Graph class The graph class keeps track of the upstream and downstream neighbors of each target. The scheduler adds edges to the graph when new targets are created dynamically. The graph is implemented as two adjacency lists: one for upstream edges and another for downstream edges. For the purposes of powering a pipeline, we find this low-tech structure to be more efficient than igraph in our situation where we repeatedly query the graph and the number of nodes is small. (Transient igraph objects, however, are created for validation and visualization purposes.) 3.5 Progress class The progress class keeps track of the state of each target: queued, running, skipped, built, outdated, canceled, or errored. To accomplish this, the progress object maintains a counter object for each category. 3.6 Queue class The queue class is a priority queue, essentially a wrapper around a named integer vector of ranks. For targets’ purposes, the rank of a target is the number of unmet dependencies so far, minus a per-target priority value in the interval [0, 1) to control the order in which targets are dequeued. As the pipeline progresses, the queue is checked and modified periodically as dependencies are met. The next target to build is the lowest rank target such that -1L &lt; rank &lt;= 0L. Branches are pushed to the queue when they are dynamically created. 3.7 Counter class A counter is an efficient abstraction for keeping track of target membership in a category. A counter stores the number of targets in the category and a hash table with the names of those targets. Counters are used to efficiently keep track of runtime progress (e.g. running, queued, or built) as well membership in the queue. 3.8 Target class A target is an abstract class for a step of a pipeline. Each target is a composite of intricate sub-classes that keep track of commands, in-memory dependencies, storage, settings, and some aspects of build behavior. As its name implies, the targets package pushes most of its conceptual complexity to the target level in order to decentralize the architecture and make it much easier to reason about the pipeline as a whole. There are multiple sub-classes of targets, and the different behaviors of different sub-classes drive the orchestration and branching of targets. The inheritance hierarchy is as follows. Target Bud Builder Stem Branch Pattern 3.9 Stem class A stem is the most basic form of target. It is neither a pattern nor part of a pattern. However, it can dynamically create buds to assist with branching. 3.10 Bud class A bud is a target that simply contains part of a stem’s value in memory. The purpose of a bud is to serve as a dependency of a branch when a pattern branches over a stem. 3.11 Pattern class A pattern is an abstract class responsible for creating new branches and dynamically updating the scheduler. Stems and patterns are the only targets the user manually defines in the pipeline. 3.12 Branch class A branch is a target that a pattern creates dynamically at runtime. 3.13 Builder class Stems and branches have a lot in common: they actually run R commands, and the write the return values to storage. A builder is an abstract class to contain the heavy lifting that stems and branches both do. 3.14 Junction class A junction is a manifest of the buds or branches (children) that a stem or pattern dynamically creates, and it depends on the user-specified pattern argument to tar_target(), e.g. tar_target(..., pattern = cross(x, map(y, z))). "],["composition.html", "Chapter 4 The composition of target objects 4.1 Overall structure 4.2 Classes 4.3 Metrics class", " Chapter 4 The composition of target objects Most of the package’s conceptual challenges and intricacies are expressed in the \"target\" class, and this decentralization helps targets effectively reason about entire pipelines. This vignette describes the classes that form the building blocks of a target. 4.1 Overall structure To maximize performance, classes with many instances per workflow are simple environments. Most of these objects lack explicit S3 class attributes, but all of them have formal constructors, helpers, and validators. The following classes define specialized objects for the fields of targets. Command Settings Cache Memory Value Metrics Store File Subpipeline Junction Pedigree Cue Some types of targets need only some of these objects as fields. Field Builder Stem Branch Bud Pattern Command ✓ ✓ ✓ ✓ ✓ Settings ✓ ✓ ✓ ✓ ✓ Cache ✓ ✓ ✓ ✓ ✓ Value ✓ ✓ ✓ ✓ ✓ Metrics ✓ ✓ ✓ Store ✓ ✓ ✓ Subpipeline ✓ ✓ ✓ Junction ✓ ✓ Pedigree ✓ ✓ Cue ✓ ✓ ✓ Patternview ✓ The class inheritance hierarchy of targets is below, and the orchestration vignette explains why the package is designed this way. Target Bud Builder Stem Branch Pattern 4.2 Classes 4.2.1 Command class A command object is an abstraction around an R code chunk. It contains an R expression, the names of packages and object dependencies that the expression needs to in order to run, the random seed to run it with, and a string and hash of the expression. The hash is used to help determine if the target is already up to date. 4.2.2 Settings class A settings object keeps track of the user-defined target-specific configuration settings of the targets, such as the target name, storage format, failure mode, memory management behavior, and branching pattern specification (if applicable). 4.2.3 Cache class The cache holds the in-memory objects that a command needs in order to run. It contains two memory objects: one for global objects (“imports”) and another for targets. The targets field requires the most maintenance because this is where a target’s upstream dependencies get loaded and unloaded. The package performs a tricky balancing act because a target needs all its dependencies loaded into memory and the time of building, but superfluous objects need to be regularly cleared out in order to conserve resources. Also, buds and branches are loaded under the name of the parent so the command’s expression does not need to change during branching. 4.2.4 Memory class A memory object is an efficient abstraction around an environment. It contains the environment itself and the names of the objects inside. This layer of abstraction allows us to avoid repeated calls to names(), thus increasing performance. 4.2.5 Value class The value class, also covered in the oop vignette, is a layer around a target’s return value. Having a special value object allows us to easily distinguish between two situations: The target did not run or load data from storage yet. The target did run, but its expression returned NULL. Without a special value class, both (1) and (2) would result in NULL values. But for (1), we have an empty value object instead of NULL. In addition, the value class has sub-classes for different data iteration/aggregation methods. Users can choose either list-like aggregation and slicing or vctrs-powered aggregation and slicing. This functionality comes in handy for branching. 4.3 Metrics class A metrics object stores metadata metrics about the instance of a target’s build, including runtime, as well as warnings, error messages, and tracebacks if applicable. Initially, the metrics object is creates as part of a build object, which is returned by a command object when it is run. Very soon after, the metrics and return value are separated out from the build object and placed directly in the target object. 4.3.1 Store class A store object describes how a target stores and queries its return value in file system storage. It contains a file object, as well as methods for managing the file, such as reading, writing, and decisions that involve hashes. The user-selected format of the target in settings determines the sub-class of the store. 4.3.2 File class A file object is an abstraction of a collection of files and directories. It contains the paths, as well as the hash, maximum time stamp, and total storage size of the aggregate. The latter two metrics help decide whether to recompute a computationally expensive hash or trust that the hash is already up to date. 4.3.3 Subpipeline A subpipeline is not actually a class of its own, it is just a pipeline object with only the direct dependencies of a particular target and no values or cache objects in those dependencies. Its only purpose is to efficiently assist with the mechanics of worker-side retrieval. 4.3.4 Junction class A junction serves as a branching specification for patterns and a budding specification for stems. It contains the name of the parent pattern or stem, the names of the children (buds or branches), and the names of the dependencies of each bud or branch. The junction is the explicit representation of the user-defined pattern argument of tar_target() combined with the hashes of the available dependencies. 4.3.5 Pedigree class Whereas junctions are branching specifications for stems and patterns, pedigrees are branching specifications for buds and branches. A pedigree has the name of the parent (pattern or stem) the name of the child (bud or branch) and the integer index of the child in the parent’s junction. 4.3.6 Cue class A cue object is a collection of rules for deciding whether a target is up to date. targets allows the user to activate or suppress some of these rules to change the conditions under which targets rerun. 4.3.7 Patternview class A patternview object keeps track of the overall status of a all a pattern’s branches as a group. Its helps make it more efficient to keep track of the progress, runtime, and storage size of an entire pattern. "],["orchestration.html", "Chapter 5 Orchestration 5.1 Decrement the ranks of downstream targets in the priority queue. 5.2 Insert new targets dynamically.", " Chapter 5 Orchestration The targets package runs the correct targets in the correct order (orchestration) and creates new targets dynamically at runtime (branching). This vignette describes the underlying package structure and mental model that gives targets its flexibility and parallel efficiency. To orchestrate targets, we iterate on the following loop while there is still at least one target in the queue. If the target at the head of the queue is not ready to build (rank &gt; 0) sleep for a short time. If the target at the head of the queue is ready to build (rank = 0) do the following: Dequeue the target. Run the target’s prepare() method. Run the target’s run() method. Run the target’s conclude() method to updates the whole scheduler. Unload transient targets from memory. The usual behavior of prepare(), run(), and conclude() is as follows. Method Responsibilities prepare() Announce the target to the console, load dependencies into memory, and register the target as running. run() Run the R command and create an object to contain the results. conclude() Store the value and update the scheduler, create new buds and branches as needed, and register the target as built. The specific behavior of prepare(), run(), and conclude() depends on the sub-class of the target. For example, run() does nontrivial work in builders (stems and branches) but does nothing in all other classes. The conclude() method is where stems and patterns update the scheduler and spawn new buds and branches dynamically. Two of the most important responsibilities of conclude() are Decrement the ranks of downstream targets in the priority queue. Insert new targets dynamically. For patterns, conclude() is called twice: once to spawn branches, and then again when all the branches are done. 5.1 Decrement the ranks of downstream targets in the priority queue. The conclude() method decrements ranks in the priority queue to signal that downstream neighbors are one step closer to being ready to build. Most targets decrement all their downstream neighbors, but a pattern only decrement the neighbors that branch over it. This behavior for patterns is key because it allows future patterns to quickly define new branches before the current ones even start running, which contributes to parallel efficiency. 5.2 Insert new targets dynamically. targets creates new targets dynamically when stems and patterns conclude. To illustrate, let us use the following example pipeline. # _targets.R library(targets) source(&quot;functions.R&quot;) # Defines all the functions below prefixed with &quot;user_&quot;. list( tar_target(data1, user_data1()), tar_target(data2, list(user_data2_slice1(), user_data2_slice2())), tar_target(analysis, user_analyze(data1, data2), pattern = map(data2)), tar_target(validation, user_validate(analysis), pattern = map(analysis)), tar_target(summary, user_summarize(validation)) # Does not map over validation. ) In prose: The data and data2 targets are starting datasets. The analysis target maps over the rows of data2 and performs a statistical analysis on each row. All analyses use the entirety of data1. The validation target maps over the analyses to check each one for correctness. The summary target aggregates and summarizes all the analyses and validations together. Graphical representation: 5.2.1 Insert buds Upon conclusion, data2 creates buds to help its downstream neighbor analysis map over it later on. data1 creates no buds because no pattern branches over it. To insert the buds, we: Create a new junction with the names of the buds to create. Create new bud objects, each containing a slice of data2’s return value. Insert the buds into the pipeline object. We do not need to update the scheduler because the parent stem of the buds already completed. In other words, buds are born built. They exist as separate data objects in memory, but they have no dedicated storage. 5.2.2 Insert branches With the buds in place, the analysis pattern can now create branches that depend on each of the respective buds of data2. After they run, the branches exist as separate data objects in memory and storage. The full aggregated analysis pattern is not needed, so it is never created. As soon as these first branches are created, we can create the branches for validation. It does not matter if analysis_5c77a278 and analysis_3439bce3 are both still queued. In addition, as soon as analysis_5c77a278 is built, validation_0f7f2822 can start building regardless of whether analysis_3439bce3 is complete. This is a major source of parallel efficiency. Notice that we never draw edges from the validation_* branches to summary. This is because summary does not map over validation, so it automatically takes in all of validation as an entire aggregated pattern. In the prepare() method of summary, validation is constructed from its individual branches kept in memory while it is needed. Unlike the validation_* branches, the aggregated validation pattern does not persist in storage. The fine details of the branching algorithm are as follows. First we create a junction to describe the branches we will create based on the user-supplied pattern argument to tar_target(). Create and insert those new branches into the pipeline. Draw graph edges to connect the branches to their individual upstream dependencies (buds or branches). Insert graph edges from the new branches to their parent pattern. Some targets may use the entire pattern in aggregate instead of iterating over individual branches, and this step makes sure all the branches are available for aggregation before a downstream target needs to use the aggregate. Push the branches onto the priority queue. The rank for each branch is the number of upstream dependencies that still need to be checked or built. 1. Increment the priority queue ranks of all downstream non-branching targets by the number of new branches just created minus 1. This ensures all the branches complete before any target calls upon the entire aggregate of the pattern. Register the branches as queued in the scheduler. Push the pattern itself back onto the queue, where the priority queue rank now equals the number of branches minus a constant between 0 and 1. (The subtracted constant just ensures the pattern gets cleaned up as soon as possible.) This step ensures we revisit the pattern after all the branches are done. At that moment, we decrement the priority queue rank of every downstream target that depends on the entire aggregated pattern (as opposed to just a single branch). This behavior drives implicit aggregation, and it ensures we do not need a special combine() pattern directive to accompany map() and cross(). "]]
